# ğŸ¤– WombGuard AI Models Setup Guide

## ğŸ“¦ **Model Files Required**

The WombGuard Platform uses **3 large AI models** for the chatbot functionality. These models are **NOT included in the git repository** due to their size (418 MB each, ~1.2 GB total).

---

## ğŸ“¥ **Download Models from GitHub Releases**

### **Step 1: Download Model Files**

Go to the [GitHub Releases page](https://github.com/YOUR_USERNAME/wombguard-platform/releases) and download the following files from the latest release:

1. **model_general_finetuned.zip** (418 MB)
2. **model_medical_finetuned.zip** (418 MB)
3. **model_qa_finetuned.zip** (418 MB)

---

### **Step 2: Extract Models**

Extract the downloaded ZIP files into the correct directories:

```bash
# Navigate to project directory
cd wombguard_platform

# Extract models (macOS/Linux)
unzip model_general_finetuned.zip -d wombguardbot_models/
unzip model_medical_finetuned.zip -d wombguardbot_models/
unzip model_qa_finetuned.zip -d wombguardbot_models/

# For Windows (PowerShell)
Expand-Archive -Path model_general_finetuned.zip -DestinationPath wombguardbot_models/
Expand-Archive -Path model_medical_finetuned.zip -DestinationPath wombguardbot_models/
Expand-Archive -Path model_qa_finetuned.zip -DestinationPath wombguardbot_models/
```

---

### **Step 3: Verify Installation**

After extraction, your directory structure should look like this:

```
wombguard_platform/
â””â”€â”€ wombguardbot_models/
    â”œâ”€â”€ model_general_finetuned/
    â”‚   â”œâ”€â”€ model.safetensors (418 MB)
    â”‚   â”œâ”€â”€ config.json
    â”‚   â”œâ”€â”€ tokenizer_config.json
    â”‚   â””â”€â”€ ... (other files)
    â”œâ”€â”€ model_medical_finetuned/
    â”‚   â”œâ”€â”€ model.safetensors (418 MB)
    â”‚   â”œâ”€â”€ config.json
    â”‚   â””â”€â”€ ... (other files)
    â”œâ”€â”€ model_qa_finetuned/
    â”‚   â”œâ”€â”€ model.safetensors (418 MB)
    â”‚   â”œâ”€â”€ config.json
    â”‚   â””â”€â”€ ... (other files)
    â”œâ”€â”€ bm25_index.pkl
    â”œâ”€â”€ embeddings_ensemble.npy
    â””â”€â”€ wombguardbot_dataset/
```

---

### **Step 4: Test Models**

Run the backend server to verify models are loaded correctly:

```bash
cd wombguard_predictive_api
python main.py
```

You should see in the logs:
```
INFO: Loaded model_general_finetuned
INFO: Loaded model_medical_finetuned
INFO: Loaded model_qa_finetuned
```

---

## ğŸ”§ **Alternative: Manual Download**

If you have the original model files, place them manually:

1. Create directories if they don't exist:
   ```bash
   mkdir -p wombguardbot_models/model_general_finetuned
   mkdir -p wombguardbot_models/model_medical_finetuned
   mkdir -p wombguardbot_models/model_qa_finetuned
   ```

2. Copy `model.safetensors` files to respective directories

---

## â“ **Troubleshooting**

### **Models Not Loading**
- Check file paths match the structure above
- Verify `model.safetensors` files are present
- Check file permissions (should be readable)

### **Out of Memory**
- Models require ~1.5 GB RAM to load
- Close other applications if needed
- Consider using a machine with more RAM

### **Download Failed**
- Large files may timeout on slow connections
- Try downloading again
- Use a download manager for reliability

---

## ğŸ“Š **Model Information**

| Model | Size | Purpose |
|-------|------|---------|
| **model_general_finetuned** | 418 MB | General pregnancy questions |
| **model_medical_finetuned** | 418 MB | Medical/clinical questions |
| **model_qa_finetuned** | 418 MB | Q&A format questions |

**Total Size:** ~1.2 GB

---

## ğŸš€ **Why Models Are Separate**

- GitHub has a 100 MB file size limit for regular commits
- Large files slow down git operations
- Users who only want to view code don't need to download models
- Easier to update models independently

---

## ğŸ“ **For Developers**

If you're training new models or updating existing ones:

1. Train your models
2. Create ZIP files:
   ```bash
   cd wombguardbot_models
   zip -r model_general_finetuned.zip model_general_finetuned/
   zip -r model_medical_finetuned.zip model_medical_finetuned/
   zip -r model_qa_finetuned.zip model_qa_finetuned/
   ```
3. Upload to GitHub Releases
4. Update release notes with model version info

---

## âœ… **Next Steps**

After models are installed:
1. âœ… Follow the main [README.md](README.md) for full setup
2. âœ… Install Python dependencies
3. âœ… Configure environment variables
4. âœ… Run the application

---

**Need help?** Open an issue on GitHub or contact the maintainers.

